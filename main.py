#!/usr/bin/env python3
"""
main.py
HlavnÃ­ orchestrÃ¡tor NSS crawleru - zjednoduÅ¡enÃ¡ demonstraÄnÃ­ verze
"""

import logging
import sys
from datetime import datetime
from pathlib import Path

# Import modulÅ¯
from models import Decision, CrawlerStats
from config import *

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class NSSCrawler:
    """HlavnÃ­ tÅ™Ã­da crawleru"""

    def __init__(self):
        self.stats = CrawlerStats()
        logger.info("Crawler inicializovÃ¡n")

    def run(self) -> CrawlerStats:
        """SpustÃ­ celÃ½ crawler pipeline"""
        logger.info("="*60)
        logger.info("ğŸš€ SPOUÅ TÃM NSS CRAWLER")
        logger.info("="*60)

        try:
            # FÃ¡ze 1: VyhledÃ¡vÃ¡nÃ­
            self._search_phase()

            # FÃ¡ze 2: StahovÃ¡nÃ­
            self._download_phase()

            # FÃ¡ze 3: OCR zpracovÃ¡nÃ­
            self._ocr_phase()

            # FÃ¡ze 4: Indexace
            self._index_phase()

            # FÃ¡ze 5: Export
            self._export_phase()

        except Exception as e:
            logger.error(f"KritickÃ¡ chyba: {e}")
            self.stats.errors += 1

        finally:
            self.stats.end_time = datetime.now()
            self._print_final_stats()

        return self.stats

    def _search_phase(self):
        """FÃ¡ze 1: VyhledÃ¡vÃ¡nÃ­"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ FÃZE 1: VYHLEDÃVÃNÃ")
        logger.info("="*60)

        logger.info(f"KlÃ­ÄovÃ¡ slova: {', '.join(KEYWORDS)}")
        logger.info(f"Max vÃ½sledkÅ¯ na klÃ­ÄovÃ© slovo: {MAX_RESULTS_PER_KEYWORD}")

        if DEBUG_MODE:
            logger.warning("âš ï¸  DEBUG MODE - PouÅ¾Ã­vÃ¡m mock data")
            # Simulace nalezenÃ­ rozhodnutÃ­
            mock_decisions = [
                Decision(
                    ecli=f"ECLI:CZ:NSS:2025:TEST.{i}",
                    title=f"TestovacÃ­ rozhodnutÃ­ {i}",
                    date=datetime.now(),
                    url=f"https://example.com/{i}",
                    keywords=KEYWORDS[:1]
                )
                for i in range(5)
            ]
            self.stats.decisions_found = len(mock_decisions)
            logger.info(f"âœ… Nalezeno {len(mock_decisions)} rozhodnutÃ­ (MOCK)")
        else:
            logger.info("ğŸŒ Crawling NSS webu...")
            logger.warning("âš ï¸  Pro plnou funkÄnost implementujte search_nss.py")
            self.stats.decisions_found = 0

    def _download_phase(self):
        """FÃ¡ze 2: StahovÃ¡nÃ­"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ FÃZE 2: STAHOVÃNÃ")
        logger.info("="*60)

        if self.stats.decisions_found > 0:
            logger.info(f"ğŸ“¥ Stahuji {self.stats.decisions_found} rozhodnutÃ­...")
            logger.info(f"âš™ï¸  Paralelizace: {MAX_WORKERS_DOWNLOAD} vlÃ¡ken")
            self.stats.decisions_downloaded = self.stats.decisions_found
            logger.info("âœ… StahovÃ¡nÃ­ dokonÄeno")
        else:
            logger.info("â­ï¸  PÅ™eskakuji - Å¾Ã¡dnÃ¡ rozhodnutÃ­ k staÅ¾enÃ­")

    def _ocr_phase(self):
        """FÃ¡ze 3: OCR zpracovÃ¡nÃ­"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ FÃZE 3: OCR ZPRACOVÃNÃ")
        logger.info("="*60)

        if PDF_OCR_ENABLED:
            logger.info(f"ğŸ” OCR jazyk: {OCR_LANGUAGE}")
            logger.info(f"âš™ï¸  Paralelizace: {MAX_WORKERS_OCR} procesÅ¯")

            if self.stats.decisions_downloaded > 0:
                logger.info(f"ğŸ“ ZpracovÃ¡vÃ¡m {self.stats.decisions_downloaded} PDF...")
                self.stats.decisions_ocr_processed = self.stats.decisions_downloaded
                logger.info("âœ… OCR dokonÄeno")
            else:
                logger.info("â­ï¸  PÅ™eskakuji - Å¾Ã¡dnÃ© PDF k zpracovÃ¡nÃ­")
        else:
            logger.warning("âš ï¸  OCR vypnuto")

    def _index_phase(self):
        """FÃ¡ze 4: Indexace"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ FÃZE 4: INDEXACE")
        logger.info("="*60)

        if USE_ELASTICSEARCH:
            logger.info(f"ğŸ” Elasticsearch: {ELASTICSEARCH_HOST}:{ELASTICSEARCH_PORT}")
            logger.info(f"ğŸ“Š Index: {ELASTICSEARCH_INDEX}")
        else:
            logger.info(f"ğŸ—„ï¸  SQLite databÃ¡ze: {DB_PATH}")

        if self.stats.decisions_ocr_processed > 0:
            logger.info(f"ğŸ“‡ Indexuji {self.stats.decisions_ocr_processed} rozhodnutÃ­...")
            self.stats.decisions_indexed = self.stats.decisions_ocr_processed
            logger.info("âœ… Indexace dokonÄena")
        else:
            logger.info("â­ï¸  PÅ™eskakuji - Å¾Ã¡dnÃ¡ rozhodnutÃ­ k indexaci")

    def _export_phase(self):
        """FÃ¡ze 5: Export (POVINNÃ)"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ FÃZE 5: EXPORT (POVINNÃ)")
        logger.info("="*60)

        logger.info(f"ğŸ“¦ Export formÃ¡t: {EXPORT_FORMAT}")
        logger.info(f"ğŸ“„ Jeden soubor: {EXPORT_SINGLE_FILE}")
        logger.info(f"ğŸ—‚ï¸  Metadata: {EXPORT_METADATA}")

        if self.stats.decisions_indexed > 0:
            export_file = EXPORT_PATH / f"nss_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
            logger.info(f"ğŸ’¾ Export do: {export_file}")
            logger.info("âœ… Export dokonÄen")
        else:
            logger.info("â­ï¸  PÅ™eskakuji - Å¾Ã¡dnÃ¡ rozhodnutÃ­ k exportu")

    def _print_final_stats(self):
        """VypÃ­Å¡e finÃ¡lnÃ­ statistiky"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š FINÃLNÃ STATISTIKY")
        logger.info("="*60)
        logger.info(self.stats)
        logger.info("="*60)


def main():
    """HlavnÃ­ funkce"""
    crawler = NSSCrawler()
    stats = crawler.run()

    # Exit code podle vÃ½sledku
    if stats.errors > 0:
        logger.error("âŒ Crawler dokonÄen s chybami")
        sys.exit(1)
    else:
        logger.info("âœ… Crawler dokonÄen ÃºspÄ›Å¡nÄ›")
        sys.exit(0)


if __name__ == "__main__":
    main()
